{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "#import sys\n",
    "#import lib\n",
    "#sys.modules[\"src.lib\"] = lib\n",
    "\n",
    "\"\"\" Alpaca Paper Trade with the 1st LSTM \"\"\"\n",
    "\n",
    "import os\n",
    "\n",
    "if \"src\" not in os.listdir():\n",
    "    os.chdir(\"../../../\")\n",
    "\n",
    "import json\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "from pytz import timezone\n",
    "import pickle\n",
    "import warnings\n",
    "\n",
    "import pandas_market_calendars as mcal\n",
    "from keras.models import load_model\n",
    "\n",
    "from src.lib.alpaca_historical import AlpacaData\n",
    "from src.lib.alpaca_paper import AlpacaTrader\n",
    "from src.lib.activations import negative_softmax\n",
    "from src.lib.price_history import transform_price_history, PriceHistory\n",
    "from src.lib.stock_dataset import StockDataset\n",
    "from src.lib.util import makedir_to"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "path = \"results/1_lstm_ptrade/\"\n",
    "keys = \"alpaca_config.json\"\n",
    "isPaper = True"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "def now_utc():\n",
    "    return datetime.now().astimezone(tz=timezone(\"UTC\"))\n",
    "\n",
    "\n",
    "def get_next_trading_minute():\n",
    "    nyse = mcal.get_calendar(\"NYSE\")\n",
    "    now = now_utc()\n",
    "    lookahead = timedelta(days=0)\n",
    "    while True:\n",
    "        lookahead += timedelta(hours=1)\n",
    "\n",
    "        schedule = nyse.schedule(start_date=now, end_date=now + lookahead)\n",
    "\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\")\n",
    "            # PerformanceWarning: Adding/subtracting object-dtype array to TimedeltaArray not vectorized\n",
    "            valid_minutes = mcal.date_range(schedule, frequency=\"1T\")            \n",
    "        \n",
    "        where_future = np.where(valid_minutes > now)[0]\n",
    "        if len(where_future) > 0:\n",
    "            break\n",
    "\n",
    "    return valid_minutes[where_future[0]]\n",
    "    # return (now + timedelta(minutes=1)).replace(second=0)\n",
    "\n",
    "def get_last_n_minutes(n_valid):\n",
    "    nyse = mcal.get_calendar(\"NYSE\")\n",
    "    now = now_utc()\n",
    "    lookbehind = timedelta(days=0)\n",
    "    n_iter = 0\n",
    "    while True:\n",
    "        lookbehind += timedelta(minutes=n_valid * 2**n_iter)\n",
    "        n_iter += 1\n",
    "\n",
    "        schedule = nyse.schedule(start_date=now - lookbehind, end_date=now)\n",
    "\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\")\n",
    "            # PerformanceWarning: Adding/subtracting object-dtype array to TimedeltaArray not vectorized\n",
    "            valid_minutes = mcal.date_range(schedule, frequency=\"1T\")            \n",
    "        \n",
    "        where_past = np.where(valid_minutes < now)[0]\n",
    "        if len(where_past) > n_valid:\n",
    "            break\n",
    "\n",
    "    return valid_minutes[where_past[-n_valid:]]\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "api_data = AlpacaData(keys)\n",
    "api_trade = AlpacaTrader(keys, isPaper)\n",
    "model = load_model(\n",
    "    os.path.join(path, \"model.h5\"),\n",
    "    custom_objects={\n",
    "        \"negative_softmax\": negative_softmax\n",
    "    }\n",
    ")\n",
    "\n",
    "with open(os.path.join(path, \"config.json\"), \"r\") as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "n_time_steps = config[\"n_time_steps\"]\n",
    "symbols = config[\"symbols\"]\n",
    "target_column = config[\"target_column\"]\n",
    "\n",
    "with open(os.path.join(path, \"scaler.pkl\"), \"rb\") as f:\n",
    "    scaler = pickle.load(f)\n",
    "\n",
    "ta_preprocess_candles = 296"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "def trade_loop():\n",
    "\n",
    "    valid_mins = get_last_n_minutes(ta_preprocess_candles + 60)\n",
    "    data_start_time = valid_mins[0]\n",
    "\n",
    "    # Sleep until next trading time\n",
    "    next_trade_time = get_next_trading_minute()\n",
    "    sleep_seconds = (next_trade_time - now_utc()).total_seconds() + 1\n",
    "    print(\"Sleeping for\", timedelta(seconds=sleep_seconds))\n",
    "    time.sleep(sleep_seconds)\n",
    "\n",
    "\n",
    "    # Get the recent data\n",
    "    price_histories = []\n",
    "    for symbol in symbols:\n",
    "        history = api_data.get_bars(symbol, data_start_time, next_trade_time, log=False)\n",
    "        if len(history) == 0:\n",
    "            print(f\"Warning: No data between {data_start_time} and {next_trade_time}\")\n",
    "            return\n",
    "        price_history = PriceHistory(history, symbol)\n",
    "        # TODO accept **kwargs here\n",
    "        price_history = transform_price_history(price_history)\n",
    "        price_histories.append(price_history)\n",
    "    \n",
    "    # Process the candes\n",
    "    dataset = StockDataset(price_histories, target_column, n_time_steps)\n",
    "    dataset = dataset.apply_standard_scaler(scaler)\n",
    "    X = dataset.prediction_X(n_time_steps)\n",
    "    \n",
    "    # Model makes predictions\n",
    "    preds = model.predict(X)[0]\n",
    "    next_holdings = dict(zip(symbols, preds))\n",
    "    print(\"Desired holdings\", next_holdings)\n",
    "    responses = api_trade.update_holdings(next_holdings, verbose=True)\n",
    "\n",
    "    # What prices did we get when we bought/sold for this step of trading\n",
    "\n",
    "    now_str = str(now_utc())\n",
    "\n",
    "    with open(os.path.join(path, \"trade_log.txt\"), \"a\") as f:\n",
    "        f.write(\"%s,%s,%s\\n\" % (now_str, str(next_holdings), str(responses)))\n",
    "    \n",
    "    X_save_path = os.path.join(path, \"Xs\", f\"{now_str}.npy\")\n",
    "    makedir_to(X_save_path)\n",
    "    np.save(X_save_path, X)\n",
    "\n",
    "while True:\n",
    "    trade_loop()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Sleeping for 0:00:52.144770\n",
      "[[[-0.25359217  0.11395504  1.18376562 ... -0.2759208  -0.04549325\n",
      "   -0.42162314]\n",
      "  [-0.24842915  0.26996267 -1.39941472 ... -0.16870055 -0.1280151\n",
      "    1.09614065]\n",
      "  [ 0.02780912  0.80927937  0.8607908  ... -0.16651187 -0.09872076\n",
      "   -1.00828528]\n",
      "  ...\n",
      "  [ 0.14265715  1.09948711 -0.24371864 ... -0.02171473  0.02001277\n",
      "    1.04639093]\n",
      "  [ 0.46754652  1.18587843 -1.0813799  ...  0.03097295  0.00259486\n",
      "    1.36254633]\n",
      "  [ 1.75449306  2.25444682 -0.94671613 ...  0.09282913  0.02135466\n",
      "    1.40045106]]]\n",
      "Desired holdings {'SPY': -0.46013662, 'SPXS': -0.53961116}\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('tf_arm': conda)"
  },
  "interpreter": {
   "hash": "aad12466045a1575aa1be41a0534cd7508fda1531bcc5a3693dc9ed3be064607"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}